\section{Distribution and Density}

\key{Distribution} is the probability induced by a random variable \(X\), such that \(\mu(A) = P\pqty{X \in A}\). \key{Density} is defined via some methods(\yellow{To be added}). It's used to change measure, for example,
\begin{equation*}
    \int g(X) \dd{P} = \int g(x)f(x)\dd{x}
\end{equation*}
the latter being the Lebesgue integral over \(\mathbb{R}\) to be defined \yellow{later}.

\section{Independence}

\subsection{Definition}

Independence is the first concept that has nontrivial meaning in probability other than inheriting measure theoretical names. 

The independence is defined via the \(\sigma\)-algebras. Let \(\pqty{\Omega, \mathcal{F}, P}\) be a probability space. A collection of sub-\(\sigma\)-algebras \(\pqty{\mathcal{F}_{\alpha}}\) are independent if for all finite subcollection, for all \(F_{1}, F_{2}, \dots, F_{n} \in\mathcal{F}_{1}, \mathcal{F}_{2}, \dots \mathcal{F}_{n}\)
\begin{equation*}
    P\pqty{F_{1} F_{2}} = P(F_{1}) P(F_{2}) \dots P \pqty{F_{n}}
\end{equation*}

Can we extend this concept? For countable collection of sub-\(\sigma\)-algebras, \(\pqty{\mathcal{F}_{n}}\), it's \key{independency} if for any finite collection \(F_{j} \in \mathcal{F}_{j}\) we have 
\begin{equation*}
    P\pqty{\bigcap_{j}^{J} F_{j}} = \prod_{j} P \pqty{F_{j}}
\end{equation*}

What about uncountable, let's assume it can be defined in the same way. 

There are several questions: can we find independency, how can we show that two \(\sigma\)-algebras are independent. 

\subsection{Sufficient Condition for Independence}

Let \(\mathcal{P}_{1}, \dots, \mathcal{P}_{n}\) be collections of measurable subsets, we say they are \textit{independent} if for all \(A_{k}\in \mathcal{P}_{k}\)
\begin{equation*}
    P\pqty{\cap A_{k} } = \prod_{k}^{n} P(A_{k})
\end{equation*}

\begin{thm}[\(\pi\)-system determines independence]
    If \(\mathcal{P}_{k}\) are independent \(\pi\)-systems, then \(\sigma\pqty{\mathcal{P}_{k}}\) are independent. 
\end{thm}

\begin{proof}
    Uses \(\pi- \lambda\) theorem.
\end{proof}



The use of independence is that if \(\sigma(X_{n})\) are independent, then we have for any measurable functions of \(X_{n}\), then we have 
\begin{equation*}
    \int f_{1}\pqty{X_{1}} f_{2}\pqty{X_{2}} \dots f_{n}\pqty{X_{n}} \dd{P} = \int f_{1}\pqty{X_{1}} \dd{P} \dots \int f_{n}\pqty{X_{n}} \dd{P}
\end{equation*}

This is related to the Fubini-Tonelli theorem in that we know the joint distribution will be the product measure of each distribution.

The Kolmogorov's Extension Theorem asserts that we can find infinite sequence of independent random variables that are consistent on \textbf{nice} spaces. 


For a sequence of sub-\(\sigma\)-algebras \(\mathcal{F}_{n} \subset \mathcal{F}\), let \(\mathcal{F}'_{m} = \sigma\pqty{\cup_{n\geq m} \mathcal{F}_{n}}\) the \key{tail \(\sigma\)-algebra} \(\mathcal{T}\) is defined as \(\cap_{m}^{\infty} \mathcal{F}'_{m}\). It's the \(\sigma\)-algebra that contains the events about the limits. 

For independent \(\sigma\)-algebras, the tail \(\sigma\)-algebra is simple, by the Kolmogorov's 0-1 law. 

\begin{thm}[Kolmogorov's 0-1 Law]
    
\end{thm}

\section{Law of Large Numbers}

For the weak laws we need to control for \(P\pqty{S_{n} \geq \epsilon \delta(n)}\). Moment can be used(Chebyshev). For the strong law we can use the Borel-Cantelli lemma. 

\subsection{Weak Law of Large Numbers}

\key{Truncation} or \key{equivalent sequence} will be important for our purpose because it guarantees the existence of moments. Let \(X_{1},\dots, X_{n}\) be a sequence of random variables. Let \(Y_{n} = X_{n}\mathbf{1}_{X_{n} \leq M}\). Then Chebyshev's inequlaity will be used.

\begin{thm}[Weak Law of Large Numbers]
    Suppose \(X_{n}\) are a sequence of random variables, satisfying that \(X_{n}\)
    \begin{enumerate}
        \item \(\sum_{k} P \pqty{X_{n} \geq k} < \infty\);
        \item 
    \end{enumerate}
\end{thm}

\subsection{Strong Law of Large Numbers}

\section{Convergence of Random Series}

The \key{Kronecker's Lemma} provides a bridge between convergence of series and the strong law of large numbers. 
\begin{lemma}[Kronecker's Lemma]
    If \(\sum \frac{a_{n}}{b_{n}} < \infty\) and \(b_{n} \uparrow \infty\), then \(\frac{1}{b_{n}} \sum a_{n} \to 0\) a.s.
\end{lemma}




\section{Central Limit Theorem}